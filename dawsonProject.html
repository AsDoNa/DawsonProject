<!DOCTYPE html>
<html>
<head>
<title>Dawson Project</title>
<meta charset="UTF-8">
<meta name="description" content="Dawson project">
<meta name="author" content="Asher Nagler (9R2)">
<style>
* {
	margin: 0;
}
h1 {
	color:#99CCFF;
	font-size: 50px;
	font-weight: bold;
}
#title {
	background-color:#000066;
	text-align:center;
	height: 100px;
	position: fixed;
	width: 100%;
}
#subtitle {
	color:#CCFFFF;
	text-align:center;
	font-size: 20px;
	font-style: italic;
}
h2 {
	font-family: Arial, sans-serif;
	font-size: 30px;
}
p {
	font-size: 25px;
}
figcaption {
    font-size: 15px;
	font-variant: small-caps;
    font-weight: bold;
	width: 300px;
}
figure {
	float: right;
	padding: 10px;
}
footer {
	text-align: center;
	height: 100px;
	width: 100%;
	background-color: #4bc2eb;
	font-size: 25px;
	color: #FFFFFF;
	position: fixed;
	left: 0;
	bottom:0;
}
footer a {
	color: #090966;
	text-decoration: none;
}
#content {
	padding-top: 100px;
	padding-left: 10px;
	padding-right: 10px;
	line-height: 1.3;
	padding-bottom: 100px;
}
</style>
</head>
<body>
<a name="top"></a>
<div id='title'>
<h1>What does the future of AI 	hold for us - Can we trust it?</h1>
<p id='subtitle'>by Asher Nagler 9R2</p>
</div>
<hr />
<div id="content">
	<figure>
		<img src='oldWheel.jpg' width='150px' height='150px' alt="From the Wheel..." />
		<img src='newIphone.jpg' width='150px' height='150px' alt="...To the iPhone" />
		<figcaption>Images 1:1 & 1:2 - From the wheel... To the iPhone</figcaption>
	</figure>
	<a name="theHistoryOfAI" tabindex="1"><h2>The History Of AI - Introduction</h2></a>
	<br />
	<p>Humans have been innovating and inventing since we began life on earth. From the wheel to mobile phones, we have created the world around us that sustains the life we live today. 
		The sweeping tide of development has been quickened by technology and as we move into another decade, that trend seems to be continuing with AI. Just as mobile phones and computers before it, AI is set to revolutionise the world in the coming years and with it comes consequences.
		In this project, I will explore AI developments in areas such as Labour, Justice and Marketing. 
		I will examine in all of these: the developments; the consequences (positive and negative); and what we must do to ensure that the developments are beneficial for humanity as a whole.</p>
	<br />
	<a name="theSingularity" tabindex="2"><h2>The Singularity - How AI will come about</h2></a>
	<figure>
		<img src="graphIntelligenceExplosion.png" width='350px' height='160px' alt="The kinetics of an intelligence explosion" />
		<figcaption id="imgCap1">Graph 2:1 - A graph showing the kinetics of an intelligence explosion<sup>[<a href="#superintelligenceGraph">1</a>]</sup></figcaption>
	</figure>
	<br />
	<p>The technological singularity is a point in time when growth in technology accelerates to such a speed that it is irreversible. The term was first popularised by Vernor Vinge in an essay <sup>[<a href="#vingeTechnologicalSingularity">2</a>]</sup>. 
		When I talk about artificial intelligence in this context, I mean artificial general intelligence (AGI) which is an AI capable of doing everything that humans can do at least as well as humans can. 
		The development of an AGI would spark	 what I.J. Good called an intelligence explosion in which the AI starts a loop of recursive self-improvement culminating in an Artificial superintelligence (ASI) and triggering what Vinge called a singularity. 
		As seen in graph 2:1, once the AI reaches the human baseline and becomes AGI, it only needs little pushes from us, and once it has reached the crossover point, it will self-improve exponentially. This will start the age of AI in which this technology will fulfil its potential as the 'last thing humans will ever have to invent' <sup>[<a href='#goodQuote'>3</a>]</sup>. 
		A superintelligence can choose to sustain human life and do whatever we need it to do, if it is benevolent, or it could otherwise cause undesirable outcomes.
		We must, therefore, follow the example of the Future Of Life institute (<a href="https://www.futureoflife.org" target="_blank">FLI<img src="https://i.stack.imgur.com/ZsU8V.png" alt="[new window icon]"></a>), whose global AI policy aims to ensure that a benevolent AI arises, whose goals include ensuring the survival and development of humanity.</p>
	<br />
	<a name="forWorkers" tabindex="3"><h2>For Workers - labour</h2></a>
	<figure>
		<img src="participationRate.png" width='350px' height='160px' alt="The participation rate of workers in the US in the last 70 years" />
		<figcaption>Graph 3:1 - The participation rate of workers in the US in the last 70 years<sup>[<a href="#participationRate">4</a>]</sup></figcaption>
	</figure>
	<br />
	<p>Businesses need to profit to survive and therefore, most businesses' aims are to maximise profit. We are already seeing people with low-skill jobs being replaced by robots who can do the job more efficiently, and cheaper than them. 
		Automating some jobs which may be dull or involve damaging physical work is one example of progress; however, AI can also remove jobs that provide people with enough money to provide for their family.   
		This, in turn, leads to rising rates of unemployment, which increases inequality between rich and poor. If jobs slowly become automated as the population grows; this is a recipe for disaster. 
		The government has to take action to prioritise AI systems that work alongside humans rather than replacing humans. If this does not happen, we may see massive jumps in unemployment and a crash in the economy as the supply of these products rise but the demand falls. 
		As shown in graph 3:1, the participation rate of workers in the US has fallen since the turn of the millennium, and it looks set to fall further as AI becomes better at low-skill jobs than humans. 
		Therefore, we must accept that as AI grows and eventually overtakes humans in all areas, there will come a point at which it becomes preferable to companies to employ AI instead of humans; given that humans have much higher employment costs than AI. 
		We must find ways to make it preferable - or if not, force - the companies to employ humans. For example, taxes on internet usage or AI development.</p>
	<br />
	<a name="inJustice" tabindex="4"><h2>In Justice</h2></a>
	<figure>
		<img src="facialRecognition.jpg" width='300px' height='160px' alt="The Metropolitan Police are starting to trial live facial recognition (LFR) which should allow them to cut down crime rates" />
		<figcaption>Image 3:1 - The Metropolitan Police are starting to trial live facial recognition (LFR) which should allow them to cut down crime rates, however it is recieving massive public backlash due to the conflicts with the civil right of privacy. <sup>[<a href="#MetropolitanPolice">5</a>]</sup></figcaption>
	</figure>
	<br />
	<p>AI development is a catalyst in decreasing crime rates. As facial recognition software develops, it will become much easier to catch criminals. With cameras everywhere, there would be nowhere for these criminals to hide. 
		However, we must question how far the government is allowed to go in its surveillance before it becomes a breach of our privacy. The government can use models to predict who is likely to commit a crime which seems to be positive, as evidenced by falling crime rates.
		This can be likened to the 2002 film, <em>Minority Report</em><sup>[<a href="#minorityReport">6</a>][<a href="#minorityReport2">7</a>]</sup> and George Orwell's <em>1984</em><sup>[<a href="#1984">8</a>]</sup>.
		We must, though, work to ensure that biases based on race etc. are not allowed to creep into the system. There have already been tests in using AI to decide how long prison sentences should be, and one advantage is the elimination of variation in sentences due to the Judge's mood.
		However, it also considers information which would not normally affect the case such as the crime rate of family members. This is unfair as it punishes the poor who live in rougher areas and so are exposed to more crime. 
		This can also cause a negative feedback cycle in that the computer decides a course of action which is not validated, and which is then given back to the computer as data to reference; this being one of the downsides of AI systems, which are systems which make decisions based on analysed data. 
		As well as that, we are seeing a rise in tracking technology which can be used to validate claims and alibis. One of the questions is, should the government have access to private data and messages to prevent crime?
		Privacy is a right, so I believe that there should only be limited use of tracking, and even then, only once a warrant has been granted. We have to be careful in the technology-filled world of the future because with the advent of ASI, we could see the death of privacy.</p>
	<br />
	<a name="inMarketing" tabindex="5"><h2>In Marketing</h2></a>
	<figure>
		<img src="youtubeRecommended.png" width='300px' height='150px' alt="YouTube's 'recommended' section uses algorithms to predict what videos are most appealing to the user" />
		<figcaption>Image 4:1 - YouTube's 'recommended' section uses algorithms to predict what videos are most appealing to the user</figcaption>
	</figure>
	<br />
	<p>As AI grows in popularity, it is becoming increasingly easy to mine data from consumers in order to advertise more efficiently. This, however, can be questioned in terms of ethics - how far can they go before it becomes an invasion of our privacy? 
		Marketeers use data to improve their target marketing: they take big data to optimise the ads that they show you in that they are relevant to you. Advertisers are using big data such as search histories to determine which ads they show you. 
		For instance, on Expedia, an advertiser would want to know if you had been on the website before and how often. If you are a loyal customer, then they would advertise their best deals to you; but if you have not shopped there before, they may send you an advertisement for a different company which if you click, they earn tiny amounts of money from. 
		As advertisers are trying to maximise profits, sometimes we can come across the dark side of advertising. These are the advertisers who try to mislead people into spending lots of money on products that they don't need. They take advantage of vulnerabilities such as those in wealth and age and they target the most susceptible. </p>
	<p>Take the college situation in the USA for example, people whose data, e.g. search history, suggests that they are not wealthy are targeted with ads for for-profit universities which do not have credibility. This takes advantage of the belief that the only way out of the poverty trap is through education. 
		Advertisers strike at the vulnerable and hit them where it hurts; for instance, if they have suffered a loss, the advertiser would say 'come to this college because we can help you deal with loss'. This tactic is becoming easier and easier to use with the rise of AI systems which target people based on their search history and other available information.
		As AI spreads, more and more of our personal information is available to advertisers who can deduce from that when and how to pounce and push us into purchases that we do not really need. They are not only taking advantage of the poor - the people who live in the wealthiest areas and have search histories suggesting wealth are also targeted for ads but in their case, for luxury goods that they probably would not even want. 
		To prevent this, we need to take action to stop data being sold and to limit the data companies can take. We need to take steps to eliminate these biased AIs working for advertisers.</p>
	<br />
	<a name="modelling" tabindex="6"><h2>AI Learning Systems And Regulation</h2></a>
	<br />
	<p>As we all know, humans by our very nature try to minimise the amount of work we have to do to produce the same outcome. This is where technology comes in; it is an innovation which could finally end the need for human labour. However, we must work to ensure that we experience only the positives. 
		Systems, or models, are created which use big data to train AIs to recognise data, and these are used increasingly in many fields and they can pose a serious risk to privacy. Advertisers are gaining more and more data about our lives as we transition into the age of AI and we have to ensure that privacy lives through it. 
		As more of our lives become online, we have become increasingly vulnerable to data-mining and we must ensure that there are rules set in place, such as the Data Protection Act Of 2018, Britain's implementation of the General Data Protection Regulation (GDPR).
		This act states that you have the right to 'stop or restrict the processing of your data' and 'be informed about how your data is being used' while companies have to ensure the information is used 'fairly, lawfully and transparently', for 'specified, explicit purposes...in a way that is adequate, relevant and limited to only what is necessary'. 
		Companies can also be held liable for your data and they have to ensure it is 'handled in a way that ensures appropriate security, including protection against unlawful or unauthorised processing, access, loss, destruction or damage' <sup>[<a href="#dataProtectionAct">9</a>]</sup>.</p>
	<br />
	<p>The reason this personal data is taken, is to train these companies' algorithms to sort data. This is key in cutting costs as it enables these companies to cut the number of humans working on tasks which are automatable. 
		For example, companies involved in mass recruitment now use these models in scanning through CVs to sift out the most promising candidates. This can also be used in personality tests from which the AI can determine which candidates are not suitable for the job. 
		However, if all companies start prioritising the same criteria, we could find some people with 'undesirable qualities' unable to get even a minimum wage job through no fault of their own. 
		We need to ensure that systems take the steps to sacrifice some efficiency for the sake of fairness or we will see a growing divide in the economy between the wealthy who get wealthier, and the rest, who cannot. 
		However, models can be used for good, for example, the model which helps speech recognition work to allow people with speech-affecting diseases to speak again.</p>
	<br />
	<a name="conclusion" tabindex="7"><h2>Conclusion</h2></a>
	<br />
	<p>I believe that AI is a force for good and we can trust its development however we have to keep an eye on its developers as they hold the real power. The governments of the world need to work to ensure that AI follows paths that are beneficial for all humanity. 
		Governments must act quickly to impose regulations to protect the world from development of negative AI-based developments, such as weapons. As AI develops, we need to take the utmost care in monitoring AI development. 
		AI right now may be under our control, but with a superintelligent or even maybe a human-level artificial general intelligence, there is a definite possibility of AI breaking out and just like that, we lose control. 
		We have survived as a species by evolving to be the smartest beings on the planet; However, with AI on the horizon, this could be the end for us.</p>
	<br />
	<hr />
	<a name="bibliography" tabindex="8"><h2>Bibliography</h2></a>
	<p><sup>[1]</sup>Tegmark, M., 2017. <em>Life 3.0: Being human in the age of artificial intelligence</em>. Knopf.<br />
	<sup>[2]</sup>Ford, M., 2015. <em>Rise of the Robots: Technology and the Threat of a Jobless Future</em>. Basic Books.<br />
	<sup>[3]</sup>Hawking, S., Russell, S., Wilczek, F., & Tegmark, M., 2014. <em>Stephen Hawking:“Trascendence looks at the implications of artificial intelligence”, but Are We Taking AI Seriously Enough?</em>. The Independent, 2.<br />
	<sup>[4]</sup>Bostrom, N., 2014. <em>Superintelligence: paths, dangers, strategies</em>. Oxford University Press.</p>
	<h2 tabindex="9">References</h2>
	<p><a name="superintelligenceGraph" tabindex="10">&#x2303<sup>[1]</sup>Bostrom, N., 2014. <em>Superintelligence: paths, dangers, strategies</em>. Oxford University Press.<br />
	<a name="vingeTechnologicalSingularity" tabindex="11">&#x2303<sup>[2]</sup>Vinge, V., 1993. <em>The coming technological singularity: How to survive in the post-human era</em>. Science Fiction Criticism: An Anthology of Essential Writings, pp.352-363.</a> <br />
	<a name="goodQuote" tabindex="12">&#x2303<sup>[3]</sup>Good I.J., 1965. <em>Speculations Concerning the First Ultraintelligent Machine</em>. Advances in Computers, vol. 6.<br />
	<a name="participationRate" tabindex="13">&#x2303<sup>[4]</sup>U.S. Bureau of Labor Statistics, December 25, 2019, <em>Labor Force Participation Rate [CIVPART]</em>, retrieved from FRED, Federal Reserve Bank of St. Louis; </a><a href="https://fred.stlouisfed.org/series/CIVPART" target="_blank">https://fred.stlouisfed.org/series/CIVPART<img src="https://i.stack.imgur.com/ZsU8V.png" alt="[new window icon]"></a>.<br />
	<a name="MetropolitanPolice" tabindex="14">&#x2303<sup>[5]</sup>The Metropolitan Police, 2020, <em>Live Facial Recognition | The Met</em>, </a><a href="https://www.met.police.uk/advice/advice-and-information/facial-recognition/live-facial-recognition/" target="_blank">https://www.met.police.uk/advice/advice-and-information/facial-recognition/live-facial-recognition/<img src="https://i.stack.imgur.com/ZsU8V.png" alt="[new window icon]"></a>.<br />
	<a name="minorityReport" tabindex="15">&#x2303<sup>[6]</sup>2002 Film <em>Minority Report</em>, </a><a href="https://en.wikipedia.org/wiki/Minority_Report_(film)" target="_blank">https://en.wikipedia.org/wiki/Minority_Report_(film)<img src="https://i.stack.imgur.com/ZsU8V.png" alt="[new window icon]"></a>.<br />
	<a name="minorityReport2" tabindex="16">&#x2303<sup>[7]</sup>Dick, P.K., 1956. <em>Minority report</em>. London: Gollancz.</a><br />
	<a name="1984" tabindex="17">&#x2303<sup>[8]</sup>Orwell, G., 1949. <em>1984</em>. London: Secker and Waldburg.</a><br />
	<a name="dataProtectionAct" tabindex="18">&#x2303<sup>[9]</sup> By law of the Data Protection Act 2018; </a><a href="https://gov.uk/data-protection" target="_blank">https://www.gov.uk/data-protection<img src="https://i.stack.imgur.com/ZsU8V.png" alt="[new window icon]"></a></p>
</div>
<footer>
	<p><a href="#theHistoryOfAI">The History Of AI</a> | <a href="#theSingularity">The Singularity</a> | <a href="#forWorkers">For Workers - Labour</a> | <a href="#inJustice">In Justice</a> | <a href="#inMarketing">In Marketing</a> | <a href="#modelling">AI Learning Systems And Regulation</a> | <a href="#conclusion">Conclusion</a> | <a href="#bibliography">Bibliography</a></p>
	<p><a href="#top">Back To Top</a></p>
	<p>What does the future of AI hold for us - can we trust it? - <em>Asher Nagler</em></p>
</footer>
</div>
</body>
</html>